\documentclass{article}
\begin{document}

\begin{center}
	\textbf{Review of Sebastian Martin Youngs hand-in}\\
\end{center}

You never describe the sigmoid derivative and what it is used for.\\This could have further supported the section about the "neuron" and why it's a better choice for neural networks.\\

The Delta Rule Derivation section is hard to make sense of, it would be better suited for reading and understanding if examples were given and how the rule derivation applies to neutral networks in terms of benefits.\\

The Error Function section is very shallow, it gives only the general overview of how it is applied in neural networks. Also a pre-understanding of how a "feedforward neutral network" normally functions is required for the last sentence to make any sense.\\

Gradient descent section is good, although the mathematical explanation is vague.

\begin{center}
	Grade: \textbf{4}
\end{center}

\end{document}
